{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeccb8e4-0101-47de-810f-60e4cb2c02c6",
   "metadata": {},
   "source": [
    "# Tester service\n",
    "\n",
    "FastAPI uses ASGI and asyncio to provide asynchronous server capabilities.\n",
    "\n",
    "Here, we do an analysis on how FastAPI is properly used and how it performs against a similar Flask setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b143de33-d050-40b7-ae24-192d8f691d8e",
   "metadata": {},
   "source": [
    "We want to measure a few metrics:\n",
    "\n",
    "- Flask/Gunicorn vs FastAPI/Uvicorn on a control test with a CPU bound task (to ensure similar serverside execution times). Metrics : number of spawned processes and performance on N requests where N > workers-count.  \n",
    "- Flask vs FastAPI with IO bound tasks. Metrics : number of spawned processes and performance on N requests where N > workers-count.  \n",
    "- FastAPI bad use-cases vs proper async usage given a CPU bound task.  \n",
    "- Additionally we look at how FastAPI and Uvicorn spawn processes on the server machine under different usage contexts (ex: development with reload vs production with no reload).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf493352-6dea-47c8-8212-31e342d4360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import asyncio\n",
    "import httpx\n",
    "from time import perf_counter\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e31e3b-6f73-462b-9eb6-7fc8e4352972",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84118e28-da9c-47ad-9f70-3526f42f0edc",
   "metadata": {},
   "source": [
    "## Tests design\n",
    "\n",
    "We use a Tester service and 3 Target Services (can be expanded to more cases):\n",
    "- Tester : Jupyter notebook with analysis.\n",
    "- Target-FastAPI:  FastAPI app served over Uvicorn app server configured as single worker.  \n",
    "- Target-FlaskSingle:  Flask app served over Gunicorn app server configured for 1xCPU cores.  \n",
    "- Target-FlaskDual:  Flask app served over Gunicorn app server configured for 2xCPU cores.  \n",
    "\n",
    "All services run under the same Docker network and are accessible via docker DNS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3e335d8-b53e-43ce-be23-512e0c66733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses Docker DNS for service addressing\n",
    "FASTAPI_SERVICE = \"fastapianalytics:5000\"\n",
    "FLASK_SINGLE_SERVICE = \"flask1xanalytics:5000\"\n",
    "FLASK_DUAL_SERVICE = \"flask2xanalytics:5000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83fcc60e-366a-41a0-9631-f9a97842fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LONG_HTTP_TIMEOUT = 300 # seconds -> for long CPU bound runs, adjust http timeouts. \n",
    "# Async calls that run sync on server (badly configured async) need to be totalled up because they are scheduled and start together but a blocked server\n",
    "# will run them sequentially, so the timeouts will add up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78182ec7-81e2-4434-9f47-c41a698d4e15",
   "metadata": {},
   "source": [
    "## Test APIs\n",
    "\n",
    "All target services provide the same API urls for synchronous requests.  \n",
    "Only FastAPI target provides the async test apis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65ecb57-9a12-4ed2-853c-d204aa866ba0",
   "metadata": {},
   "source": [
    "### Calibration step\n",
    "The first test is actually a calibration to server-machine resources: we run this to get an evaluation on how long the server needs for one calculation (varies with available CPU and memory, external processes, ..). \n",
    "\n",
    "### Baseline duration\n",
    "Based on the calibration value we can then determine the number of iterations required to have a specific duration for server operations.\n",
    "\n",
    "### Performance Test configuration\n",
    "Each test then sends a specific number of requests to a target, where each request is configured to have a specific duration for the serverside processing (i.e. each request takes X seconds to process serverside) .\n",
    "\n",
    "The tests are run in sequence, not parallel on the target servers. This is because we are using a single physical machine (services run in a Docker Network hosted on one machine) and services will compete for resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "918c1725-c205-40d5-ae94-72dc62f7067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CALIBRATION_API = \"test/calibrate\"\n",
    "SYNC_API_PERFORMANCE = \"test/sync-cpubound/{}\" # format the string and add specific duration for each test\n",
    "BAD_ASYNC_API_PERFORMANCE = \"test/badasync-cpubound/{}\" # ONLY on the FastAPI, Flask is always synchronous\n",
    "RESMON_API = \"test/resmon\" # format the string and add specific duration for each test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86c42db-5ed7-431b-818c-6d5a7da15fc8",
   "metadata": {},
   "source": [
    "Set up a convenience function to construct our urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc76ead2-557c-4236-bf46-6a4b3be067ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://fastapianalytics:5000/test/calibrate\n",
      "http://fastapianalytics:5000/test/sync-cpubound/2\n"
     ]
    }
   ],
   "source": [
    "def get_url(service, api, iterations=None):\n",
    "    partial = '/'.join(['http:/', service, api])\n",
    "    return partial.format(iterations) if iterations else partial\n",
    "# TESTS\n",
    "print(get_url(FASTAPI_SERVICE, CALIBRATION_API))\n",
    "print(get_url(FASTAPI_SERVICE, SYNC_API_PERFORMANCE, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12567c95-20f4-4db7-a0b7-f38dac183c36",
   "metadata": {},
   "source": [
    "# Calibration CPU bound tests\n",
    "\n",
    "Since response times may vary on host performance at a given moment, use an average over N requests to determine calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2a0a8de-4b2e-4121-a068-9ff9b7922234",
   "metadata": {},
   "outputs": [],
   "source": [
    "AVGSAMPLES_FOR_CALIB = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d98632-d7fd-4df4-a5fd-1fd21019a6b5",
   "metadata": {},
   "source": [
    "Prepare a convenience function to send http requests with or without iterations parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e754d4fd-de1a-4335-932c-34bc59dbf5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "async def http_send_async(url, client: aiohttp.ClientSession, iterations:int=0):\n",
    "        async with client.get(url) as resp:\n",
    "            return await resp.json()\n",
    "\n",
    "# async with aiohttp.ClientSession() as client:\n",
    "#     result = await http_send_async(get_url(FASTAPI_SERVICE, CALIBRATION_API), client)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92828744-b7f1-40ef-b061-2ba41f8e16e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "async def http_send_async(url, client: httpx.AsyncClient, iterations:int=0):\n",
    "    # await asyncio.sleep(2)\n",
    "    await client.get(url, timeout= LONG_HTTP_TIMEOUT)\n",
    "    # response.raise_for_status()  # Raise an exception for bad status codes\n",
    "    # return response.json()\n",
    "\n",
    "# TEST\n",
    "async with httpx.AsyncClient() as client:\n",
    "   result = await http_send_async(get_url(FASTAPI_SERVICE, CALIBRATION_API), client)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa2221b9-9321-45fe-993c-f0c7f12422ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': '--------\\n Received at: 2025-01-04T18:21:59.555367 -- Duration of 50 iterations', 'result': 1.4475434509986371}\n",
      "{'message': '--------\\n Received at: 2025-01-04T18:21:58.064120 -- Duration of 50 iterations', 'result': 1.488456185998075}\n",
      "{'message': '--------\\n Received at: 2025-01-04T18:22:02.403109 -- Duration of 50 iterations', 'result': 1.5088864329991338}\n",
      "{'message': '--------\\n Received at: 2025-01-04T18:22:01.003626 -- Duration of 50 iterations', 'result': 1.3974660179992497}\n",
      "{'message': '--------\\n Received at: 2025-01-04T18:21:56.403780 -- Duration of 50 iterations', 'result': 1.6578565609997895}\n",
      "7.521668965000572\n"
     ]
    }
   ],
   "source": [
    "limits = httpx.Limits(max_keepalive_connections=20, max_connections=20)\n",
    "# async def send_n_concurrent_requests(n:int, url: str)-> dict:\n",
    "async def send_n_concurrent_requests(loop: asyncio.AbstractEventLoop, n:int, url: str)-> dict:\n",
    "    \"\"\"\n",
    "    Schedules N concurrent async http requests on the running event loop\n",
    "    \"\"\"\n",
    "    async with httpx.AsyncClient(limits=limits) as client:\n",
    "        requests =[client.get(url, timeout= LONG_HTTP_TIMEOUT) for _ in range(n)]\n",
    "        results = await asyncio.gather(*requests)\n",
    "\n",
    "    #------------\n",
    "    # async with aiohttp.ClientSession() as client:\n",
    "        \n",
    "        # tasks = [loop.create_task(http_send_async(url, client)) for _ in range(n)]\n",
    "        # print('After tasks creation: ', len(asyncio.all_tasks()))\n",
    "        # results= await asyncio.gather(*tasks)\n",
    "\n",
    "        print(*[r.json() for r in results], sep='\\n')\n",
    "# TESTS\n",
    "start= perf_counter()\n",
    "results = await send_n_concurrent_requests(asyncio.get_event_loop(), 5, get_url(FASTAPI_SERVICE, SYNC_API_PERFORMANCE, 50))\n",
    "# task = asyncio.get_running_loop().create_task(send_n_concurrent_requests( 10, get_url(FASTAPI_SERVICE, SYNC_API_PERFORMANCE, 50)))\n",
    "# await task\n",
    "end= perf_counter()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4525a332-7788-4bf6-98b6-5aeca6793a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of 50 - duration on single iteration: 0.03297409542014065 seconds\n"
     ]
    }
   ],
   "source": [
    "async def avg_iteration_times(ntests: int, url:str, iterations:int=0):\n",
    "    \"\"\"\n",
    "    Send requests to the target url ntests time and average the returned iteration durations\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        for _ in range(ntests):\n",
    "            res = await http_send_async(url, client) # this will trigger exception for errors\n",
    "            total +=res.get('result')\n",
    "\n",
    "    return total/ntests\n",
    "# TESTS\n",
    "fa_iter_d = await avg_iteration_times(AVGSAMPLES_FOR_CALIB, get_url(FASTAPI_SERVICE, CALIBRATION_API))\n",
    "print(f'Average of {AVGSAMPLES_FOR_CALIB} - duration on single iteration: {fa_iter_d} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2fb08f-bb37-41d6-90d5-cd04f1d566bc",
   "metadata": {},
   "source": [
    "### Fast API Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6afa195d-8ec9-482d-8bb4-648d6514904d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of 50 runs - duration on single iteration: 0.03413210183993215 seconds\n"
     ]
    }
   ],
   "source": [
    "fa_iter_d = await avg_iteration_times(AVGSAMPLES_FOR_CALIB, get_url(FASTAPI_SERVICE, CALIBRATION_API))\n",
    "print(f'Average of {AVGSAMPLES_FOR_CALIB} runs - duration on single iteration: {fa_iter_d} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879118e7-83b3-4382-88b1-731f3fe6f37a",
   "metadata": {},
   "source": [
    "### Flask targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1eda9146-5adf-46de-8e52-d5a0167313e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of 50 runs - duration on single iteration: 0.04899092547973851 seconds\n"
     ]
    }
   ],
   "source": [
    "fsk1x_iter_d = await avg_iteration_times(AVGSAMPLES_FOR_CALIB, get_url(FLASK_SINGLE_SERVICE, CALIBRATION_API))\n",
    "print(f'Average of {AVGSAMPLES_FOR_CALIB} runs - duration on single iteration: {fsk1x_iter_d} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f77dabba-330c-4d2e-8ed9-261729ad7886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of 50 runs - duration on single iteration: 0.06447064997995768 seconds\n"
     ]
    }
   ],
   "source": [
    "fsk2x_iter_d = await avg_iteration_times(AVGSAMPLES_FOR_CALIB, get_url(FLASK_DUAL_SERVICE, CALIBRATION_API))\n",
    "print(f'Average of {AVGSAMPLES_FOR_CALIB} runs - duration on single iteration: {fsk2x_iter_d} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017688ff-676f-4f5a-a135-cd94984225cb",
   "metadata": {},
   "source": [
    "### Iterations for N seconds processing time\n",
    "\n",
    "These do not reflect actual relative performance between services. The resources available for each service, when running the CPU bound task, may differ as do the actual, random values, in the test matrices.  \n",
    "The values only reflect a close approximation to how many iterations we need, on each service, to have a similarly timed computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9b9d9c74-eb5c-4325-a9e5-30915d3717d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 40, 31)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 2 # seconds\n",
    "faiter = int(N/fa_iter_d)\n",
    "fsk1xiter = int(N/fsk1x_iter_d)\n",
    "fsk2xiter = int(N/fsk2x_iter_d)\n",
    "faiter, fsk1xiter, fsk2xiter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5842dbe4-3a1a-4121-bd54-3d73b0597602",
   "metadata": {},
   "source": [
    "### Baseline resource monitor snapshot\n",
    "\n",
    "Get a snapshot of resources used on the target services, when idle but fully started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d7d4edd7-5e85-4d90-b2a9-8bcf8a767c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pcount': 4,\n",
       " 'rows': ['  PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND',\n",
       "  '    1 root      20   0   33708  28276  10140 S   0.0   0.4   0:46.99 uvicorn',\n",
       "  '    7 root      20   0   15920  11856   5952 S   0.0   0.1   0:00.03 python3.13',\n",
       "  '    8 root      20   0 1605340 260252  20576 S   0.0   3.3   0:27.51 python3.13',\n",
       "  '   45 root      20   0    9004   4680   2812 R   0.0   0.1   0:00.00 top']}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_pcount_from_resmon_str(resmonstr: str)-> int:\n",
    "    \"\"\"\n",
    "    Return a process count (assumes a default configuration of top command, i.e. is a row based parser)\n",
    "    \"\"\"\n",
    "    # scroll lines until processes header line: PID USER PR ..\n",
    "    rowlist = resmonstr.splitlines()\n",
    "    headersub = \"PID USER      PR  NI    VIRT    RES    SHR\"\n",
    "    try:\n",
    "        startidx = next(i for i, string in enumerate(rowlist) if headersub in string)\n",
    "    except StopIteration:\n",
    "        print(\"Error: missing header row or header row has different format than expected\")\n",
    "        return -1\n",
    "    \n",
    "    return {\n",
    "            \"pcount\": len(rowlist[startidx+1:]),\n",
    "            \"rows\": rowlist[startidx:]\n",
    "            }\n",
    "# TESTS\n",
    "get_pcount_from_resmon_str(fa_resmon_base.get(\"result\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "08267156-745b-43bd-a67f-86464d202d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full output:\n",
      " top - 16:04:38 up  4:27,  0 user,  load average: 0.17, 0.15, 0.17\n",
      "Tasks:   4 total,   1 running,   3 sleeping,   0 stopped,   0 zombie\n",
      "%Cpu(s):  0.0 us, 11.1 sy,  0.0 ni, 77.8 id, 11.1 wa,  0.0 hi,  0.0 si,  0.0 st \n",
      "MiB Mem :   7749.8 total,   3023.6 free,   4315.1 used,    675.0 buff/cache     \n",
      "MiB Swap:   2048.0 total,   2048.0 free,      0.0 used.   3434.7 avail Mem \n",
      "\n",
      "  PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND\n",
      "    1 root      20   0   33708  28736  10140 S   0.0   0.4   2:15.16 uvicorn\n",
      "    7 root      20   0   15920  11856   5952 S   0.0   0.1   0:00.03 python3.13\n",
      "  910 root      20   0 1605312 259304  19744 S   0.0   3.3   0:29.46 python3.13\n",
      "  942 root      20   0    9004   4720   2848 R   0.0   0.1   0:00.00 top\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pcount': 4,\n",
       " 'rows': ['  PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND',\n",
       "  '    1 root      20   0   33708  28736  10140 S   0.0   0.4   2:15.16 uvicorn',\n",
       "  '    7 root      20   0   15920  11856   5952 S   0.0   0.1   0:00.03 python3.13',\n",
       "  '  910 root      20   0 1605312 259304  19744 S   0.0   3.3   0:29.46 python3.13',\n",
       "  '  942 root      20   0    9004   4720   2848 R   0.0   0.1   0:00.00 top']}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa_resmon_base = send_http(get_url(FASTAPI_SERVICE, RESMON_API))\n",
    "print(\"Full output:\\n\", fa_resmon_base.get(\"result\"))\n",
    "get_pcount_from_resmon_str(fa_resmon_base.get(\"result\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5a92703f-0df6-456d-a1e2-50dd91e88266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full output:\n",
      " top - 16:04:38 up  4:27,  0 user,  load average: 0.17, 0.15, 0.17\n",
      "Tasks:   5 total,   1 running,   4 sleeping,   0 stopped,   0 zombie\n",
      "%Cpu(s):  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st \n",
      "MiB Mem :   7749.8 total,   3022.0 free,   4316.2 used,    675.5 buff/cache     \n",
      "MiB Swap:   2048.0 total,   2048.0 free,      0.0 used.   3433.6 avail Mem \n",
      "\n",
      "  PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND\n",
      "    9 root      20   0 1661584 243028  15884 S   6.7   3.1   0:52.18 gunicorn\n",
      "    1 root      20   0   29716  23924   9876 S   0.0   0.3   0:01.15 gunicorn\n",
      "    7 root      20   0 1661656 243080  15860 S   0.0   3.1   0:48.93 gunicorn\n",
      "    8 root      20   0 1661584 243064  15848 S   0.0   3.1   0:53.00 gunicorn\n",
      "  109 root      20   0    9004   4820   2940 R   0.0   0.1   0:00.00 top\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pcount': 5,\n",
       " 'rows': ['  PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND',\n",
       "  '    9 root      20   0 1661584 243028  15884 S   6.7   3.1   0:52.18 gunicorn',\n",
       "  '    1 root      20   0   29716  23924   9876 S   0.0   0.3   0:01.15 gunicorn',\n",
       "  '    7 root      20   0 1661656 243080  15860 S   0.0   3.1   0:48.93 gunicorn',\n",
       "  '    8 root      20   0 1661584 243064  15848 S   0.0   3.1   0:53.00 gunicorn',\n",
       "  '  109 root      20   0    9004   4820   2940 R   0.0   0.1   0:00.00 top']}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsk_1x_resmon_base = send_http(get_url(FLASK_SINGLE_SERVICE, RESMON_API))\n",
    "print(\"Full output:\\n\", fsk_1x_resmon_base.get(\"result\"))\n",
    "get_pcount_from_resmon_str(fsk_1x_resmon_base.get(\"result\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c5e9f2ef-89ce-4a04-a376-09c74c0c19c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full output:\n",
      " top - 16:04:39 up  4:27,  0 user,  load average: 0.17, 0.15, 0.17\n",
      "Tasks:   7 total,   1 running,   6 sleeping,   0 stopped,   0 zombie\n",
      "%Cpu(s):  0.0 us, 12.5 sy,  0.0 ni, 75.0 id,  0.0 wa,  0.0 hi, 12.5 si,  0.0 st \n",
      "MiB Mem :   7749.8 total,   3022.0 free,   4316.2 used,    675.5 buff/cache     \n",
      "MiB Swap:   2048.0 total,   2048.0 free,      0.0 used.   3433.7 avail Mem \n",
      "\n",
      "  PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND\n",
      "    1 root      20   0   29716  23632   9976 S   0.0   0.3   0:01.17 gunicorn\n",
      "    7 root      20   0 1661652 242476  15636 S   0.0   3.1   1:04.18 gunicorn\n",
      "   39 root      20   0 1661588 242372  15636 S   0.0   3.1   0:48.14 gunicorn\n",
      "   40 root      20   0 1661588 242352  15636 S   0.0   3.1   0:48.67 gunicorn\n",
      "   72 root      20   0 1661588 242336  15636 S   0.0   3.1   0:54.79 gunicorn\n",
      "  104 root      20   0 1661588 242336  15636 S   0.0   3.1   0:59.45 gunicorn\n",
      "  175 root      20   0    9004   4772   2896 R   0.0   0.1   0:00.00 top\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pcount': 7,\n",
       " 'rows': ['  PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND',\n",
       "  '    1 root      20   0   29716  23632   9976 S   0.0   0.3   0:01.17 gunicorn',\n",
       "  '    7 root      20   0 1661652 242476  15636 S   0.0   3.1   1:04.18 gunicorn',\n",
       "  '   39 root      20   0 1661588 242372  15636 S   0.0   3.1   0:48.14 gunicorn',\n",
       "  '   40 root      20   0 1661588 242352  15636 S   0.0   3.1   0:48.67 gunicorn',\n",
       "  '   72 root      20   0 1661588 242336  15636 S   0.0   3.1   0:54.79 gunicorn',\n",
       "  '  104 root      20   0 1661588 242336  15636 S   0.0   3.1   0:59.45 gunicorn',\n",
       "  '  175 root      20   0    9004   4772   2896 R   0.0   0.1   0:00.00 top']}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsk_2x_resmon_base = send_http(get_url(FLASK_DUAL_SERVICE, RESMON_API))\n",
    "print(\"Full output:\\n\", fsk_2x_resmon_base.get(\"result\"))\n",
    "get_pcount_from_resmon_str(fsk_2x_resmon_base.get(\"result\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a79781-707d-4fe1-8dd3-bc817919f6ed",
   "metadata": {},
   "source": [
    "# Base performance CPU bound - no parallelization\n",
    "\n",
    "This test will trigger **single requests** to synchronous apis on all targets.  \n",
    "These api-endpoints contain simple calls to CPU bound tasks, with no extra logic for parallelization.  \n",
    "Each request is parametrized to have the number of iterations required to induce a specific processing-time on the target server.  \n",
    "Here we establish a baseline for future tests where multiple requests are used to check for the target-server ability to handle concurrent requests.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1d2605c3-60ec-417f-b045-34c48f66b5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': '--------\\n Received at: 2025-01-04T16:05:07.133719 -- Duration of 58 iterations',\n",
       " 'result': 1.8057356679983059}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async with httpx.AsyncClient() as client:\n",
    "    fa_cpu_base = await http_send_async(get_url(FASTAPI_SERVICE, SYNC_API_PERFORMANCE, faiter), client)\n",
    "fa_cpu_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2abfc29b-4b9e-4e1f-a8c9-e66f89155397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Duration of 40 iterations', 'result': 1.2667629059997125}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async with httpx.AsyncClient() as client:\n",
    "    fsk1x_cpu_base =await http_send_async(get_url(FLASK_SINGLE_SERVICE, SYNC_API_PERFORMANCE, fsk1xiter), client)\n",
    "fsk1x_cpu_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d2b8943b-4f7b-46d5-99c3-64f0b90b0d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Duration of 31 iterations', 'result': 0.9445747890003986}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async with httpx.AsyncClient() as client:\n",
    "    fsk2x_cpu_base =await http_send_async(get_url(FLASK_DUAL_SERVICE, SYNC_API_PERFORMANCE, fsk2xiter), client)\n",
    "fsk2x_cpu_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5b2ccb-122f-4732-a723-df8a0abd53f5",
   "metadata": {},
   "source": [
    "The above measurements may deviate from the intended processing time, depending on the resources available on the target service container at the time of the request.  \n",
    "The main point here is to make sure requests are sent faster than they are processed, during concurrent requests tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5551a88c-1733-4be4-9e6c-0e25cb13bad5",
   "metadata": {},
   "source": [
    "# Concurrent requests tests\n",
    "\n",
    "Here, the challenge is sending concurrent requests, since the normal http_send would by synchronous and block until receiving a response.  \n",
    "To further complicate things, Jupyter is running its own event loop so we need to tap into it with our tasks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0af7e677-370d-400a-a00d-38a8b0bd8ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_UnixSelectorEventLoop running=True closed=False debug=False>\n",
      "Baseline Jupyter scheduled tasks: \n",
      "\n",
      "[('Task-3', <coroutine object Kernel.dispatch_queue at 0x7f56e4103100>)]\n"
     ]
    }
   ],
   "source": [
    "loop = asyncio.get_running_loop()\n",
    "print(loop)\n",
    "print(\"Baseline Jupyter scheduled tasks: \\n\",[(t.get_name(), t.get_coro()) for t in list(asyncio.all_tasks())], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3dd0b347-bda4-4b02-8f72-4830e67a4c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After tasks creation:  12\n",
      "17.10492639900076\n",
      "{'message': '--------\\n Received at: 2025-01-04T16:06:10.314989 -- Duration of 58 iterations', 'result': 1.7479861669999082}\n",
      "{'message': '--------\\n Received at: 2025-01-04T16:06:13.830969 -- Duration of 58 iterations', 'result': 1.7160713279990887}\n",
      "{'message': '--------\\n Received at: 2025-01-04T16:06:12.064186 -- Duration of 58 iterations', 'result': 1.7654554700002336}\n",
      "{'message': '--------\\n Received at: 2025-01-04T16:06:24.079642 -- Duration of 58 iterations', 'result': 1.6774582809994172}\n",
      "{'message': '--------\\n Received at: 2025-01-04T16:06:15.548613 -- Duration of 58 iterations', 'result': 1.6637734880005155}\n",
      "{'message': '--------\\n Received at: 2025-01-04T16:06:20.699347 -- Duration of 58 iterations', 'result': 1.6885174840008403}\n",
      "{'message': '--------\\n Received at: 2025-01-04T16:06:17.213647 -- Duration of 58 iterations', 'result': 1.7359221469996555}\n",
      "{'message': '--------\\n Received at: 2025-01-04T16:06:22.388590 -- Duration of 58 iterations', 'result': 1.6901936480007862}\n",
      "{'message': '--------\\n Received at: 2025-01-04T16:06:18.952404 -- Duration of 58 iterations', 'result': 1.7456879909987038}\n",
      "{'message': '--------\\n Received at: 2025-01-04T16:06:25.759198 -- Duration of 58 iterations', 'result': 1.6458987030000571}\n"
     ]
    }
   ],
   "source": [
    "async def send_n_concurrent_requests(loop: asyncio.AbstractEventLoop, n:int, url: str)-> dict:\n",
    "    \"\"\"\n",
    "    Schedules N concurrent async http requests on the running event loop\n",
    "    \"\"\"\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        tasks = [loop.create_task(http_send_async(url, client)) for _ in range(n)]\n",
    "        print('After tasks creation: ', len(asyncio.all_tasks()))\n",
    "        results= await asyncio.gather(*tasks)\n",
    "\n",
    "    return results\n",
    "# TESTS\n",
    "start= perf_counter()\n",
    "results = await send_n_concurrent_requests(asyncio.get_running_loop(), 10, get_url(FASTAPI_SERVICE, SYNC_API_PERFORMANCE, faiter))\n",
    "end= perf_counter()\n",
    "print(end-start, *results, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f960a56a-9df2-4fde-9326-cfb560f136e9",
   "metadata": {},
   "source": [
    "## Async requests to blocking APIs\n",
    "\n",
    "Here we test as follows.  \n",
    "The Flask services handle loads synchronously (blocking the running thread and process) but they also run multiple workers from the beginning. This means that we expect them to out-perform FastAPI on this test.  \n",
    "The api we are targetting on the FastAPI service is one where the CPU bound task is triggered directly from the api. This should result in blocking the thread & process where the event loop runs. Which means FasAPI will runn all requests in sequence, so response time should increase linearly.  \n",
    "Note : this is an improper way to trigger a CPU bound task on FastAPI so the behavior is expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6e8539-46ff-40c8-9e82-2955e4253ae3",
   "metadata": {},
   "source": [
    "### FastAPI target w blocking task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8cbd1e2d-2a41-44ea-89a0-16f9661ab689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.9264696720001666,\n",
       " 3.6781316950000473,\n",
       " 5.699639510999987,\n",
       " 7.533728120000887,\n",
       " 9.365989138999794]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa_times = []\n",
    "for n in range(1,6):\n",
    "    start= perf_counter()\n",
    "    await send_n_concurrent_requests(asyncio.get_running_loop(), n, get_url(FASTAPI_SERVICE, SYNC_API_PERFORMANCE, faiter))\n",
    "    fa_times.append(perf_counter() - start)\n",
    "\n",
    "fa_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2031e70b-50d6-4095-9d90-a5b0c8affb65",
   "metadata": {},
   "source": [
    "### Flask targets with blocking tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d9a7dd34-6c9c-44d0-9c14-62d3422c513b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.232686190000095,\n",
       " 2.566646810999373,\n",
       " 3.1656890220001515,\n",
       " 4.722645226998793,\n",
       " 5.347812461999638]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsk1x_times = []\n",
    "for n in range(1,6):\n",
    "    start= perf_counter()\n",
    "    await send_n_concurrent_requests(asyncio.get_running_loop(), n, get_url(FLASK_SINGLE_SERVICE, SYNC_API_PERFORMANCE, faiter))\n",
    "    fsk1x_times.append(perf_counter() - start)\n",
    "\n",
    "fsk1x_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "623ec4ac-b9a1-4b0f-9677-9a6b042ebbff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.8925547309991089,\n",
       " 2.375839641001221,\n",
       " 2.9147490659997857,\n",
       " 3.1490542699993966,\n",
       " 3.6605018909995124]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsk2x_times = []\n",
    "for n in range(1,6):\n",
    "    start= perf_counter()\n",
    "    await send_n_concurrent_requests(asyncio.get_running_loop(), n, get_url(FLASK_DUAL_SERVICE, SYNC_API_PERFORMANCE, faiter))\n",
    "    fsk2x_times.append(perf_counter() - start)\n",
    "\n",
    "fsk2x_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07779aa9-5863-460b-96df-a5e4b3eb8376",
   "metadata": {},
   "source": [
    "Here we see immediately the difference between the multiple running workers on the Flask-Targets vs the single worker of the FastAPI target IF this single worker is blocked by a CPU bound task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd680d5-e2d7-499f-913e-fd42c8d8d174",
   "metadata": {},
   "source": [
    "### FastAPI target with \"hidden\" blocking task\n",
    "\n",
    "Here we test a situation where a CPU bound task is nested at a deeper level on the call-tree from a FastAPI app.  \n",
    "This can happen by accident if a developer calls a CPU bound task from a proper async function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0d09e7b1-a30a-4e6a-a08b-d799465ef1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2.0685485810008686,\n",
       "  4.0416611189994,\n",
       "  5.939327529000366,\n",
       "  7.786892374000672,\n",
       "  9.707984624001256],\n",
       " {1: [{'message': 'At 2025-01-04T15:46:30.508034 -- duration for 65 iterationss',\n",
       "    'result': 2.056700623001234,\n",
       "    'concurrent_tasks': 4}],\n",
       "  2: [{'message': 'At 2025-01-04T15:46:32.577743 -- duration for 65 iterationss',\n",
       "    'result': 2.024836127000526,\n",
       "    'concurrent_tasks': 4},\n",
       "   {'message': 'At 2025-01-04T15:46:34.603504 -- duration for 65 iterationss',\n",
       "    'result': 2.0012396090005495,\n",
       "    'concurrent_tasks': 4}],\n",
       "  3: [{'message': 'At 2025-01-04T15:46:40.593607 -- duration for 65 iterationss',\n",
       "    'result': 1.9526234860004479,\n",
       "    'concurrent_tasks': 4},\n",
       "   {'message': 'At 2025-01-04T15:46:36.631524 -- duration for 65 iterationss',\n",
       "    'result': 1.933330689000286,\n",
       "    'concurrent_tasks': 4},\n",
       "   {'message': 'At 2025-01-04T15:46:38.566271 -- duration for 65 iterationss',\n",
       "    'result': 2.0244049220000306,\n",
       "    'concurrent_tasks': 4}],\n",
       "  4: [{'message': 'At 2025-01-04T15:46:44.574654 -- duration for 65 iterationss',\n",
       "    'result': 1.9361465470010444,\n",
       "    'concurrent_tasks': 4},\n",
       "   {'message': 'At 2025-01-04T15:46:48.413349 -- duration for 65 iterationss',\n",
       "    'result': 1.9191602549999516,\n",
       "    'concurrent_tasks': 4},\n",
       "   {'message': 'At 2025-01-04T15:46:46.513185 -- duration for 65 iterationss',\n",
       "    'result': 1.8994137209992914,\n",
       "    'concurrent_tasks': 5},\n",
       "   {'message': 'At 2025-01-04T15:46:42.565737 -- duration for 65 iterationss',\n",
       "    'result': 2.006450656999732,\n",
       "    'concurrent_tasks': 4}],\n",
       "  5: [{'message': 'At 2025-01-04T15:46:56.241326 -- duration for 65 iterationss',\n",
       "    'result': 1.8943854900007864,\n",
       "    'concurrent_tasks': 5},\n",
       "   {'message': 'At 2025-01-04T15:46:50.364099 -- duration for 65 iterationss',\n",
       "    'result': 1.9280638700001873,\n",
       "    'concurrent_tasks': 4},\n",
       "   {'message': 'At 2025-01-04T15:46:54.257601 -- duration for 65 iterationss',\n",
       "    'result': 1.9806009359999734,\n",
       "    'concurrent_tasks': 6},\n",
       "   {'message': 'At 2025-01-04T15:46:52.292023 -- duration for 65 iterationss',\n",
       "    'result': 1.9627046010009508,\n",
       "    'concurrent_tasks': 7},\n",
       "   {'message': 'At 2025-01-04T15:46:58.136492 -- duration for 65 iterationss',\n",
       "    'result': 1.903584743000465,\n",
       "    'concurrent_tasks': 4}]})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa_times = []\n",
    "results = dict()\n",
    "for n in range(1,6):\n",
    "    start= perf_counter()\n",
    "    results[n] = await send_n_concurrent_requests(asyncio.get_running_loop(), n, get_url(FASTAPI_SERVICE, BAD_ASYNC_API_PERFORMANCE, faiter))\n",
    "    fa_times.append(perf_counter() - start)\n",
    "\n",
    "fa_times, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c690555-83d8-493d-a0b9-eeb0be7278c9",
   "metadata": {},
   "source": [
    "We see the same performance even though each request in a burst is now scheduled to run concurrently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c645df-9d71-454e-b068-0551a31cf6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
